# Stock Trading Using a Deep Reinforcement Learning and Text Analysis

## Abstract
The thesis focuses on exploiting imperfections on the stock market by utilizing state-of-the-art learning methods and applying them to algorithmic trading. The automated decisions are expected to have the capability of outperforming professional traders by considering much more information, reacting almost
instantly and being unaffected by emotions. As an alternative to traditional supervised learning, the proposed model of reinforcement learning employs a principle of trial-and-error, which is essential for learning behaviours of all organisms. In the context of stocks, this allows to consider the involved uncertainty and therefore more precisely estimate the long-run returns. To collect the most relevant information for each trading decision, additionally to technical indicators the models build on investorâ€™s opinion - financial sentiment. This is derived from two textual sources, news and social media, and the main goal is to compare their relative contribution to trading. Models are applied to 11 different stocks and later combined into portfolio for greater robustness of results. The textual analysis proves to be important for the learning process, especially in case of stocks with good media coverage. The Twitter is found to provide more valuable information compared to news, but their combination shows even higher predictive potential. Nevertheless, proposed models have difficulties to reliably outperform passive strategies or the market.

## Notes
This is a repository of scripts and collected dataset for my diploma thesis. It describes the process of scraping the twitter as well as news textual sources, training the reinforcement agents and evaluating and visualising the results. If found interesting, the decision-making process of the trained agents can be replicated for real-world usage or used for further fine-tuning. All of the resources utilized are available here, except the web-scraped data, which can be requested on demand.
